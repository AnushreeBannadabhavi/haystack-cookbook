{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_coq_qCuItbN"
      },
      "source": [
        "# Using the Jina-embeddings-v2-base-en model in a Haystack RAG pipeline for legal document analysis\n",
        "\n",
        "One foggy day in October 2023, I was narrowly excused from jury duty. I had mixed feelings about it, since it actually seemed like a pretty interesting case (Google v. Sonos). A few months later, I idly wondered how the proceedings turned out. I could just read the news, but what's the fun in that? Let's see how AI can solve this problem.\n",
        "\n",
        "[Jina.ai](https://jina.ai/) recently released `jina-embeddings-v2-base-en`. It's an open-source text embedding model capable of accommodating up to 8192 tokens. Splitting text into larger chunks is helpful for understanding longer documents. One of the use cases this model is especially suited for is legal document analysis.\n",
        "\n",
        "In this demo, we'll build a [RAG pipeline](https://www.deepset.ai/blog/llms-retrieval-augmentation) to discover the outcome of the Google v. Sonos case, using the following technologies:\n",
        "- the [`jina-embeddings-v2-base-en`](https://arxiv.org/abs/2310.19923) model\n",
        "- [Haystack](https://haystack.deepset.ai/), the open source LLM orchestration framework, version [2.0-beta](https://docs.haystack.deepset.ai/v2.0/docs)\n",
        "- [Chroma](https://docs.trychroma.com/getting-started) to store our vector embeddings, via the [Chroma Document Store Haystack integration](https://haystack.deepset.ai/integrations/chroma-documentstore)\n",
        "- the open source [Mixtral 8x7B LLM](https://huggingface.co/docs/transformers/model_doc/mixtral)\n",
        "\n",
        "\n",
        "## Prerequisites:\n",
        "- You need a Jina AI key - [get a free one here](https://jina.ai/embeddings/).\n",
        "- You also need an [Hugging Face access token](https://huggingface.co/docs/hub/security-tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKgrm01CD3af"
      },
      "source": [
        "First, install all our required dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFbYg2Yb_UgT",
        "outputId": "0d6d6753-19bc-4e73-fb15-aa8fae5b50b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-3.17.4-py3-none-any.whl (278 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.17.4\n"
          ]
        }
      ],
      "source": [
        "!pip3 install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prmChq6T_T4l",
        "outputId": "2768c613-7cb4-4b23-de77-1c6a8cf24850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting haystack-ai\n",
            "  Downloading haystack_ai-2.0.0b3-py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.7/189.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jina-haystack\n",
            "  Downloading jina_haystack-0.0.1-py3-none-any.whl (10 kB)\n",
            "Collecting chroma-haystack\n",
            "  Downloading chroma_haystack-0.9.0-py3-none-any.whl (11 kB)\n",
            "Collecting boilerpy3 (from haystack-ai)\n",
            "  Downloading boilerpy3-1.0.7-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (3.1.2)\n",
            "Collecting lazy-imports (from haystack-ai)\n",
            "  Downloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (10.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (3.2.1)\n",
            "Collecting openai<1.0.0 (from haystack-ai)\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (1.5.3)\n",
            "Collecting posthog (from haystack-ai)\n",
            "  Downloading posthog-3.1.0-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (6.0.1)\n",
            "Collecting rank-bm25 (from haystack-ai)\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (8.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from jina-haystack) (2.31.0)\n",
            "Collecting chromadb<0.4.20 (from chroma-haystack)\n",
            "  Downloading chromadb-0.4.19-py3-none-any.whl (505 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.0/506.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.4.20->chroma-haystack) (1.10.13)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading fastapi-0.108.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading uvicorn-0.25.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.4.20->chroma-haystack) (1.23.5)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading opentelemetry_api-1.22.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.22.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading opentelemetry_sdk-1.22.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.4.20->chroma-haystack) (0.15.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading overrides-7.4.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb<0.4.20->chroma-haystack) (6.1.1)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.4.20->chroma-haystack) (1.60.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb<0.4.20->chroma-haystack) (0.9.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading kubernetes-28.1.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmh3>=4.0.1 (from chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading mmh3-4.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.6/72.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai<1.0.0->haystack-ai) (3.9.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->haystack-ai) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog->haystack-ai)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->haystack-ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from posthog->haystack-ai) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->jina-haystack) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->jina-haystack) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->jina-haystack) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->jina-haystack) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->haystack-ai) (2.1.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai) (2023.3.post1)\n",
            "Collecting starlette<0.33.0,>=0.29.0 (from fastapi>=0.95.2->chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading starlette-0.32.0.post1-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.0/70.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions (from haystack-ai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.4.20->chroma-haystack) (2.17.3)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.4.20->chroma-haystack) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.4.20->chroma-haystack) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb<0.4.20->chroma-haystack) (3.2.2)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->jina-haystack)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.4.20->chroma-haystack) (23.5.26)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.4.20->chroma-haystack) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.4.20->chroma-haystack) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb<0.4.20->chroma-haystack) (1.12)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.4.20->chroma-haystack) (1.62.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.22.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.22.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.22.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading opentelemetry_proto-1.22.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl (28 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading opentelemetry_semantic_conventions-0.43b0-py3-none-any.whl (36 kB)\n",
            "Collecting opentelemetry-util-http==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading opentelemetry_util_http-0.43b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.4.20->chroma-haystack) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.4.20->chroma-haystack) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb<0.4.20->chroma-haystack) (0.20.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb<0.4.20->chroma-haystack) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (4.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.4.20->chroma-haystack) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.4.20->chroma-haystack) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.4.20->chroma-haystack) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.4.20->chroma-haystack) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.4.20->chroma-haystack) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.4.20->chroma-haystack) (3.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.33.0,>=0.29.0->fastapi>=0.95.2->chromadb<0.4.20->chroma-haystack) (3.7.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.4.20->chroma-haystack)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.4.20->chroma-haystack) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.33.0,>=0.29.0->fastapi>=0.95.2->chromadb<0.4.20->chroma-haystack) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.33.0,>=0.29.0->fastapi>=0.95.2->chromadb<0.4.20->chroma-haystack) (1.2.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.4.20->chroma-haystack) (0.5.1)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=c9e75c3f4c2595c35e65b05e26686abf542fe6213cb7e77522b77b5c08606e06\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, urllib3, typing-extensions, rank-bm25, python-dotenv, pulsar-client, overrides, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, lazy-imports, importlib-metadata, humanfriendly, httptools, h11, deprecated, chroma-hnswlib, boilerpy3, bcrypt, backoff, watchfiles, uvicorn, starlette, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, asgiref, posthog, opentelemetry-sdk, opentelemetry-instrumentation, openai, onnxruntime, fastapi, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, kubernetes, haystack-ai, opentelemetry-instrumentation-fastapi, jina-haystack, chromadb, chroma-haystack\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 7.0.0\n",
            "    Uninstalling importlib-metadata-7.0.0:\n",
            "      Successfully uninstalled importlib-metadata-7.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.7.2 backoff-2.2.1 bcrypt-4.1.2 boilerpy3-1.0.7 chroma-haystack-0.9.0 chroma-hnswlib-0.7.3 chromadb-0.4.19 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.108.0 h11-0.14.0 haystack-ai-2.0.0b3 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-6.11.0 jina-haystack-0.0.1 kubernetes-28.1.0 lazy-imports-0.3.1 mmh3-4.0.1 monotonic-1.6 onnxruntime-1.16.3 openai-0.28.1 opentelemetry-api-1.22.0 opentelemetry-exporter-otlp-proto-common-1.22.0 opentelemetry-exporter-otlp-proto-grpc-1.22.0 opentelemetry-instrumentation-0.43b0 opentelemetry-instrumentation-asgi-0.43b0 opentelemetry-instrumentation-fastapi-0.43b0 opentelemetry-proto-1.22.0 opentelemetry-sdk-1.22.0 opentelemetry-semantic-conventions-0.43b0 opentelemetry-util-http-0.43b0 overrides-7.4.0 posthog-3.1.0 pulsar-client-3.4.0 pypika-0.48.9 python-dotenv-1.0.0 rank-bm25-0.2.2 starlette-0.32.0.post1 typing-extensions-4.9.0 urllib3-1.26.18 uvicorn-0.25.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install haystack-ai jina-haystack chroma-haystack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fGOt677EYuE"
      },
      "source": [
        "Then input our credentials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRogtDXaAMIF",
        "outputId": "79ea9fda-6595-4d74-9462-fc35ba18476f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JINA api key:··········\n",
            "Enter your HuggingFace api token:··········\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "\n",
        "jina_api_key  = getpass.getpass(\"JINA api key:\")\n",
        "hf_token = getpass.getpass(\"Enter your HuggingFace api token:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlMkLSVjJVoW"
      },
      "source": [
        "## Build an Indexing Pipeline\n",
        "\n",
        "At a high level, the `LinkContentFetcher` pulls this document from its URL. Then we convert it from a PDF into a Document object Haystack can understand.\n",
        "\n",
        "We preprocess it by removing whitespace and redundant substrings. Then split it into chunks, generate embeddings, and write these embeddings into the `ChromaDocumentStore`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "3lx84bCtM4aS",
        "outputId": "bb99c198-fb05-4c64-d5b7-192e60957d1f"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1d1e9b702df9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mchroma_haystack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_store\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChromaDocumentStore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdocument_store\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChromaDocumentStore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chroma_haystack'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from chroma_haystack.document_store import ChromaDocumentStore\n",
        "document_store = ChromaDocumentStore()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpY3UQiN07J-",
        "outputId": "77b55084-c547-4749-9745-24edf5883333"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pypdf._reader:Overwriting cache for 0 284\n",
            "WARNING:pypdf._reader:Overwriting cache for 0 284\n",
            "Calculating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: d79dce457b2db0af95dac37ae12b3b189b9831b232c96fdadab14589b77bc423\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: d79dce457b2db0af95dac37ae12b3b189b9831b232c96fdadab14589b77bc423\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 4a48bd181aba0d690fa5bb5f405b20716ddb5a9de86d60f115161770d01e319a\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 4a48bd181aba0d690fa5bb5f405b20716ddb5a9de86d60f115161770d01e319a\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: b543a4b9cc5643a119ddcdc9bd447b8693e275b7e1cefe55cbd7617c49f5acff\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: b543a4b9cc5643a119ddcdc9bd447b8693e275b7e1cefe55cbd7617c49f5acff\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 47d8ca2b2e34f0aeebc6b270cebe288490d2242ef2aa9379521647e057477d88\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 47d8ca2b2e34f0aeebc6b270cebe288490d2242ef2aa9379521647e057477d88\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 01fa852c8e38b8beb4b97b909dc4a2057f2dad0dec40c1853bc0e3af5d981f11\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 01fa852c8e38b8beb4b97b909dc4a2057f2dad0dec40c1853bc0e3af5d981f11\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: b83c39364eb8c495240753be08ed0861650b4575886e62b1eacd6a6a82545ea0\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: b83c39364eb8c495240753be08ed0861650b4575886e62b1eacd6a6a82545ea0\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 8be1894817ed07444eb7325c5deb00e0587e9704099b7ecf808d283396225b99\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 8be1894817ed07444eb7325c5deb00e0587e9704099b7ecf808d283396225b99\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: c22d35e93fddd8419a47b53898f8f5c334d30a55297f85ba50426e576e1af703\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: c22d35e93fddd8419a47b53898f8f5c334d30a55297f85ba50426e576e1af703\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 9b2b126437a28c91647e85a36e3ad4f1bb29a4f97b9a86f22c4fd39b25c741f7\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 9b2b126437a28c91647e85a36e3ad4f1bb29a4f97b9a86f22c4fd39b25c741f7\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: e3fd3ae03e4f270204a9c92291adf8f8c54264fa2455cde646f51fae60b5e2c9\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: e3fd3ae03e4f270204a9c92291adf8f8c54264fa2455cde646f51fae60b5e2c9\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 8c134f0aac73498e82d2dbcba6c083e5808425ab39daacc0c85f85091709aac5\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 8c134f0aac73498e82d2dbcba6c083e5808425ab39daacc0c85f85091709aac5\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 1871742d51cf47a9506d5d86f57bf6036a9f394d804d18d8a2ad8969749c3359\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 1871742d51cf47a9506d5d86f57bf6036a9f394d804d18d8a2ad8969749c3359\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 823f9e779436734d593d929a296d5cebdab49f5f1d3050a2660b1ddcc0834aac\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 823f9e779436734d593d929a296d5cebdab49f5f1d3050a2660b1ddcc0834aac\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: f4b881025c661752b0c7125da28793d05bc45ce03e765498945a4651beccb231\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: f4b881025c661752b0c7125da28793d05bc45ce03e765498945a4651beccb231\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: a58c4ff89fa15edbd41bd9c1a7ef7cf1bb68b6381fd2ffe40f9046d89ebe2efc\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: a58c4ff89fa15edbd41bd9c1a7ef7cf1bb68b6381fd2ffe40f9046d89ebe2efc\n",
            "WARNING:chromadb.segment.impl.vector.local_hnsw:Add of existing embedding ID: 2bb1dc1f96f6497101f7fa2a857bff3da41c818ae916c68d3e13b687d9523ac4\n",
            "WARNING:chromadb.segment.impl.metadata.sqlite:Insert of existing embedding ID: 2bb1dc1f96f6497101f7fa2a857bff3da41c818ae916c68d3e13b687d9523ac4\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'embedder': {'metadata': {'model': 'jina-embeddings-v2-base-en',\n",
              "   'usage': {'total_tokens': 11058, 'prompt_tokens': 11058}}},\n",
              " 'writer': {'documents_written': None}}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from haystack import Pipeline\n",
        "\n",
        "from haystack.components.fetchers import LinkContentFetcher\n",
        "from haystack.components.converters import PyPDFToDocument\n",
        "from haystack.components.writers import DocumentWriter\n",
        "from haystack.components.preprocessors import DocumentCleaner\n",
        "from haystack.components.preprocessors import DocumentSplitter\n",
        "from chroma_haystack.retriever import ChromaEmbeddingRetriever\n",
        "from haystack.document_stores.types import DuplicatePolicy\n",
        "\n",
        "from jina_haystack.document_embedder import JinaDocumentEmbedder\n",
        "from jina_haystack.text_embedder import JinaTextEmbedder\n",
        "\n",
        "fetcher = LinkContentFetcher()\n",
        "converter = PyPDFToDocument()\n",
        "# remove repeated substrings to get rid of headers/footers\n",
        "cleaner = DocumentCleaner(remove_repeated_substrings=True)\n",
        "\n",
        "# Since jina-v2 can handle 8192 tokens, 500 words seems like a safe chunk size\n",
        "splitter = DocumentSplitter(split_by=\"word\", split_length=500)\n",
        "\n",
        "# DuplicatePolicy.SKIP is optional but helps avoid errors if you want to re-run the pipeline\n",
        "writer = DocumentWriter(document_store=document_store, policy=DuplicatePolicy.SKIP)\n",
        "\n",
        "retriever = ChromaEmbeddingRetriever(document_store=document_store)\n",
        "\n",
        "# There are both small and large embedding models available, depending on your computing resources and requirements.\n",
        "# Here we're using the larger model.\n",
        "document_embedder = JinaDocumentEmbedder(api_key=jina_api_key, model_name=\"jina-embeddings-v2-base-en\")\n",
        "\n",
        "indexing_pipeline = Pipeline()\n",
        "indexing_pipeline.add_component(instance=fetcher, name=\"fetcher\")\n",
        "indexing_pipeline.add_component(instance=converter, name=\"converter\")\n",
        "indexing_pipeline.add_component(instance=cleaner, name=\"cleaner\")\n",
        "indexing_pipeline.add_component(instance=splitter, name=\"splitter\")\n",
        "indexing_pipeline.add_component(instance=document_embedder, name=\"embedder\")\n",
        "indexing_pipeline.add_component(instance=writer, name=\"writer\")\n",
        "\n",
        "indexing_pipeline.connect(\"fetcher.streams\", \"converter.sources\")\n",
        "indexing_pipeline.connect(\"converter.documents\", \"cleaner.documents\")\n",
        "indexing_pipeline.connect(\"cleaner.documents\", \"splitter.documents\")\n",
        "indexing_pipeline.connect(\"splitter.documents\", \"embedder.documents\")\n",
        "indexing_pipeline.connect(\"embedder.documents\", \"writer.documents\")\n",
        "\n",
        "# This case references Google V Sonos, October 2023\n",
        "urls = [\"https://cases.justia.com/federal/district-courts/california/candce/3:2020cv06754/366520/813/0.pdf\"]\n",
        "\n",
        "indexing_pipeline.run(data={\"fetcher\": {\"urls\": urls}})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvBHvwqoa3YJ"
      },
      "source": [
        "# Query pipeline\n",
        "\n",
        "Now the real fun begins. Let's create a query pipeline so we can actually start asking questions. We write a prompt allowing us to pass our documents to the Mixtral-8x7B LLM. Then we initiatialize the LLM via the `HuggingFaceTGIGenerator`.\n",
        "\n",
        "In Haystack 2.0 `retriever`s are tightly coupled to `DocumentStores`. If we pass in the `retriever` we initialized earlier, this pipeline can access those embeddings we generated, and pass them to the LLM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZefXI2cBRME"
      },
      "outputs": [],
      "source": [
        "\n",
        "from haystack.components.generators import HuggingFaceTGIGenerator\n",
        "from haystack.components.builders.prompt_builder import PromptBuilder\n",
        "\n",
        "from jina_haystack.text_embedder import JinaTextEmbedder\n",
        "prompt = \"\"\" Answer the question, based on the\n",
        "content in the documents. If you can't answer based on the documents, say so.\n",
        "\n",
        "Documents:\n",
        "{% for doc in documents %}\n",
        "  {{doc.content}}\n",
        "{% endfor %}\n",
        "\n",
        "question: {{question}}\n",
        "\"\"\"\n",
        "\n",
        "text_embedder = JinaTextEmbedder(api_key=jina_api_key, model_name=\"jina-embeddings-v2-base-en\")\n",
        "generator = HuggingFaceTGIGenerator(\"mistralai/Mixtral-8x7B-Instruct-v0.1\", token=hf_token)\n",
        "generator.warm_up()\n",
        "\n",
        "prompt_builder = PromptBuilder(template=prompt)\n",
        "query_pipeline = Pipeline()\n",
        "query_pipeline.add_component(\"text_embedder\",text_embedder)\n",
        "query_pipeline.add_component(instance=prompt_builder, name=\"prompt_builder\")\n",
        "query_pipeline.add_component(\"retriever\", retriever)\n",
        "query_pipeline.add_component(\"generator\", generator)\n",
        "\n",
        "query_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
        "query_pipeline.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
        "query_pipeline.connect(\"prompt_builder.prompt\", \"generator.prompt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuHpvfGZGB7b"
      },
      "source": [
        "Time to ask a question!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3VxIscXJMOS",
        "outputId": "f2ed03f3-efe9-44f0-e7e3-a5bdc8500c56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".\n",
            "\n",
            "Answer: Google v. Sonos is a patent infringement case in which Sonos sued Google for infringing on two of its patents related to customizing and saving overlapping groups of smart speakers or other zone players according to a common theme, and then later invoking such groups on demand. Google countersued for a declaratory judgment. The case went to trial and concluded two weeks ago. The court had deferred ruling on two of Google's motions in limine, allowing Sonos to put on the contested evidence with the understanding that the court may strike it from the record, tell the jury to disregard it, and grant one of the motions in limine under Rule 50, if appropriate. Ultimately, the court granted Google's first motion in limine and denied its second motion as moot. The court found that Sonos's damages theory was flawed and based on sleight of hand and smoke and mirrors. The court granted Google's motion to strike Sonos's damages expert's testimony and opinion.\n"
          ]
        }
      ],
      "source": [
        "question = \"Summarize what happened in Google v. Sonos\"\n",
        "\n",
        "result = query_pipeline.run(data={\"text_embedder\":{\"text\": question},\n",
        "                                  \"retriever\": {\"top_k\": 3},\n",
        "                                  \"prompt_builder\":{\"question\": question},\n",
        "                                  \"generator\": {\"generation_kwargs\": {\"max_new_tokens\": 350}}})\n",
        "\n",
        "print(result['generator']['replies'][0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJE9E6LmzEwB"
      },
      "source": [
        "### Other questions you could try:\n",
        "- What role did If This Then That play in Google v. Sonos?\n",
        "- What judge presided over Google v. Sonos?\n",
        "- What should Sonos have done differently?\n",
        "\n",
        "\n",
        "### Alternate cases to explore\n",
        "The indexing pipeline is written so that you can swap in other documents and analyze them. can You can try plugging the following URLs (or any PDF written in English) into the indexing pipeline and re-running all the code blocks below it.\n",
        "- Google v. Oracle: https://supreme.justia.com/cases/federal/us/593/18-956/case.pdf\n",
        "- JACK DANIEL’S PROPERTIES, INC. v. VIP PRODUCTS\n",
        "LLC: https://www.supremecourt.gov/opinions/22pdf/22-148_3e04.pdf\n",
        "\n",
        "Note: if you want to change the prompt template, you'll also need to re-run the code blocks starting where the `DocumentStore` is defined.\n",
        "\n",
        "### Wrapping it up\n",
        "Thanks for reading! If you're interested in learning more about the technologies used here, check out these blog posts:\n",
        "- [Embeddings in Depth](https://jina.ai/news/embeddings-in-depth/)\n",
        "- [What is text vectorization in NLP?](https://haystack.deepset.ai/blog/what-is-text-vectorization-in-nlp)\n",
        "- [The definitive guide to BERT models](https://haystack.deepset.ai/blog/the-definitive-guide-to-bertmodels)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
