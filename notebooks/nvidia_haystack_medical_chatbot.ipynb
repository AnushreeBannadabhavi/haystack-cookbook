{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "pRaykAACSbuY"
      },
      "source": [
        "\n",
        "\n",
        "# Building a healthcare chatbot with the NVIDIA Haystack integration and PubMed\n",
        "\n",
        "\n",
        "*notebook by Tilde Thurium:\n",
        " [Mastodon](https://tech.lgbt/@annthurium) || [Twitter](https://twitter.com/annthurium) || [LinkedIn](https://www.linkedin.com/in/annthurium/)*\n",
        "\n",
        "\n",
        "**Prerequisites:**\n",
        "\n",
        "*   [NVIDIA API Key](https://org.ngc.nvidia.com/setup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kobrp6O3SbuY"
      },
      "source": [
        "## Installing the NVIDIA-Haystack extension\n",
        "\n",
        "To start, let's install the latest release of `nvidia-haystack` with `pip`, as well as any other libraries we're going to need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFb8fAhmSbuY"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "!pip install nvidia-haystack==0.0.1\n",
        "pip install pymed\n",
        "pip install git+https://github.com/deepset-ai/haystack-core-integrations.git#subdirectory=integrations/nvidia"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the credentials we need and set them as an environment variable."
      ],
      "metadata": {
        "id": "gTiZXeHbpN1I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOynyZ__t_X5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "NVIDIA_API_KEY = userdata.get(\"NVIDIA_API_KEY\")\n",
        "os.environ['NVIDIA_API_KEY'] = NVIDIA_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rc2FY_Cvq8m"
      },
      "source": [
        "# PubMed Fetcher\n",
        "\n",
        "PubMed is the best source of up to date medical research. Now we are going to write our own custom class to pull scientific papers from PubMed that are relevant to the query at hand.\n",
        "\n",
        "The PubMed sdk basically just wraps the PubMed API so it's easier to query.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FELyF-Z0NT4X"
      },
      "outputs": [],
      "source": [
        "from pymed import PubMed\n",
        "from typing import List\n",
        "from haystack import component\n",
        "from haystack.dataclasses import Document\n",
        "\n",
        "\n",
        "pubmed = PubMed(tool=\"NvidiaHaystackDemo\", email=\"tilde.thurium@deepset.ai\")\n",
        "\n",
        "def documentize(article):\n",
        "  return Document(content=article.abstract, meta={'title': article.title, 'keywords': article.keywords, 'publication_date': article.publication_date})\n",
        "\n",
        "@component\n",
        "class PubMedFetcher():\n",
        "\n",
        "  @component.output_types(articles=List[Document])\n",
        "  def run(self, queries: list[str]):\n",
        "    cleaned_queries = queries[0].strip().split('\\n')\n",
        "\n",
        "    articles = []\n",
        "    try:\n",
        "      for query in cleaned_queries:\n",
        "        response = pubmed.query(query, max_results = 1)\n",
        "        documents = [documentize(article) for article in response]\n",
        "        articles.extend(documents)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(f\"Couldn't fetch articles for queries: {queries}\" )\n",
        "    results = {'articles': articles}\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiate two `NvidiaGenerator`s. One will convert the query into keywords, and the other will actually answer the query based on the documents provided."
      ],
      "metadata": {
        "id": "qtFVW4O_cmhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack_integrations.components.generators.nvidia import NvidiaGenerator, NvidiaGeneratorModel\n",
        "\n",
        "llm = NvidiaGenerator(\n",
        "    model=NvidiaGeneratorModel.NV_LLAMA2_RLHF_70B,\n",
        "    model_arguments={\n",
        "        \"temperature\": 0.2,\n",
        "        \"top_p\": 0.7,\n",
        "        \"max_tokens\": 1024,\n",
        "        \"seed\": None,\n",
        "        \"bad\": None,\n",
        "        \"stop\": None,\n",
        "    },\n",
        ")\n",
        "llm.warm_up()\n",
        "\n",
        "keyword_llm = NvidiaGenerator(\n",
        "    model=NvidiaGeneratorModel.NV_LLAMA2_RLHF_70B,\n",
        "    model_arguments={\n",
        "        \"temperature\": 0.2,\n",
        "        \"top_p\": 0.7,\n",
        "        \"max_tokens\": 1024,\n",
        "        \"seed\": None,\n",
        "        \"bad\": None,\n",
        "        \"stop\": None,\n",
        "    },\n",
        ")\n",
        "keyword_llm.warm_up()"
      ],
      "metadata": {
        "id": "lKvIKg6S1VRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, add the `PubmedFetcher` into a RAG pipeline."
      ],
      "metadata": {
        "id": "OwK9hBa-k98w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWCYd6hOpoIn"
      },
      "outputs": [],
      "source": [
        "from haystack import Pipeline\n",
        "from haystack.components.builders.prompt_builder import PromptBuilder\n",
        "\n",
        "keyword_prompt_template = \"\"\"\n",
        "Your task is to convert the following question into 3 keywords that can be used to find relevant medical research papers on PubMed.\n",
        "Here is an examples:\n",
        "question: \"What are the latest treatments for major depressive disorder?\"\n",
        "keywords:\n",
        "Antidepressive Agents\n",
        "Depressive Disorder, Major\n",
        "Treatment-Resistant depression\n",
        "---\n",
        "question: {{ question }}\n",
        "keywords:\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "Answer the question truthfully based on the given documents.\n",
        "If the documents don't contain an answer, say so.\n",
        "cite the documents you used by mentioning their article title in the answer.\n",
        "For example, begin your answer with ‘As stated in the article titled, ...’.\n",
        "\n",
        "q: {{ question }}\n",
        "Articles:\n",
        "{% for article in articles %}\n",
        "  {{article.content}}\n",
        "  keywords: {{article.meta['keywords']}}\n",
        "  title: {{article.meta['title']}}\n",
        "{% endfor %}\n",
        "\n",
        "\"\"\"\n",
        "keyword_prompt_builder = PromptBuilder(template=keyword_prompt_template)\n",
        "\n",
        "prompt_builder = PromptBuilder(template=prompt_template)\n",
        "fetcher = PubMedFetcher()\n",
        "\n",
        "pipe = Pipeline()\n",
        "\n",
        "pipe.add_component(\"keyword_prompt_builder\", keyword_prompt_builder)\n",
        "pipe.add_component(\"keyword_llm\", keyword_llm)\n",
        "pipe.add_component(\"pubmed_fetcher\", fetcher)\n",
        "pipe.add_component(\"prompt_builder\", prompt_builder)\n",
        "pipe.add_component(\"llm\", llm)\n",
        "\n",
        "pipe.connect(\"keyword_prompt_builder.prompt\", \"keyword_llm.prompt\")\n",
        "pipe.connect(\"keyword_llm.replies\", \"pubmed_fetcher.queries\")\n",
        "\n",
        "pipe.connect(\"pubmed_fetcher.articles\", \"prompt_builder.articles\")\n",
        "pipe.connect(\"prompt_builder.prompt\", \"llm.prompt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "While we're at it, let's make an `ask` method to wrap our query fetching. This method makes it easy to pull the query response out of the results."
      ],
      "metadata": {
        "id": "L1hTVeYpmVRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask(question):\n",
        "  output = pipe.run(data={\"keyword_prompt_builder\":{\"question\":question},\n",
        "                          \"prompt_builder\":{\"question\": question}})\n",
        "  print(output['llm']['replies'])\n",
        "\n"
      ],
      "metadata": {
        "id": "v6y2xvz2VJOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Give it a try!"
      ],
      "metadata": {
        "id": "pEbStD7jmb_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ask(\"How are mRNA vaccines being used for cancer treatment?\")"
      ],
      "metadata": {
        "id": "uUPghrs9Vm8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uFGaPu6yqHEs"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "bda33b16be7e844498c7c2d368d72665b4f1d165582b9547ed22a0249a29ca2e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}