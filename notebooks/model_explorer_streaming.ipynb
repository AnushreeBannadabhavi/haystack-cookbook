{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5e061067281e46c3a0e13850ded2da0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be7d41d0ba44405e84abc7cc1e32efb2",
              "IPY_MODEL_7ebcad8075f74d6f91d8ae4e105bf4b4",
              "IPY_MODEL_e606a9b359484f80b821197029c419af",
              "IPY_MODEL_c89920b1edb849b0a8625166c61e2d22",
              "IPY_MODEL_f3a8a94eba894e098414ab9ecb288588"
            ],
            "layout": "IPY_MODEL_7146c96d346d43e78e22fe663e501078"
          }
        },
        "be7d41d0ba44405e84abc7cc1e32efb2": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_eda89ff2ee0a46909205059af92ee220",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "'Model name: command'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' The  sun  dipping  beneath  the'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' horizon  akin  to  a  flat'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "'line ,  an  explosion  of'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' color  amidst  the  cloud  haze'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "',  akin  to  the  myriad'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' moods  of  cocaine .  The'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' sky  sw allows  the  day'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' whole ,  a  mystery  yet'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' to  be  solved .  '",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              }
            ]
          }
        },
        "7ebcad8075f74d6f91d8ae4e105bf4b4": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_6b13f90fe4664ae78f6e3a04a63c94aa",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "'Model name: gpt-3.5-turbo'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' As  the  golden  orb'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' descended  beneath  the  distant  horizon'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "',  painting  the  sky  a'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' tape stry  of  vibrant  hues'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\",  Nature 's  intricate  palette\"",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' was  master fully  blended .'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' The  rhyth mic  sym phony'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' of  crashing  waves  fused  with'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' gentle  whispers  of  br ine'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "'-k iss ed  winds ,'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' captivating  my  senses .  Truly'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "',  a  seaside  sunset  is'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' a  ver itable  masterpiece ,'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' soaring  on  the  wings  of'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' artistic  maj esty . '",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              }
            ]
          }
        },
        "e606a9b359484f80b821197029c419af": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_c0bb1da133254ac995a1d07320b60d5d",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "'Model name: mistralai/Mistral-7B-v0.1'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "'\\n \\n The  sun set'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' was  a  thing  of  beauty'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "',  a  sight  to  beh'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "'old .  The  sky  was'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              }
            ]
          }
        },
        "c89920b1edb849b0a8625166c61e2d22": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_a8c1ae0b06ae42deb6e777be1952e509",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "'Model name: tiiuae/falcon-7b-instruct'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "'\\n As  the  sun  dipped'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' below  the  horizon ,  a'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' brilliant  array  of  colors  painted'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' the  sky ,  ranging  from'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              }
            ]
          }
        },
        "f3a8a94eba894e098414ab9ecb288588": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_40d6dfe4bbcb4925a1d95c3fe60592a1",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "'Model name: bigscience/bloom'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "'” \\n I ’m  not'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' sure  what  the  point  of'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' this  exercise  is ,  but'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "' I  can  tell  you  that'",
                  "application/vnd.google.colaboratory.intrinsic+json": {
                    "type": "string"
                  }
                },
                "metadata": {}
              }
            ]
          }
        },
        "7146c96d346d43e78e22fe663e501078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eda89ff2ee0a46909205059af92ee220": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid black",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b13f90fe4664ae78f6e3a04a63c94aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid black",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0bb1da133254ac995a1d07320b60d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid black",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8c1ae0b06ae42deb6e777be1952e509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid black",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40d6dfe4bbcb4925a1d95c3fe60592a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid black",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Streaming model explorer for Haystack 2.0\n",
        "\n",
        "*Problem*: there are so many LLMs these days! Which model is the best for my use case?\n",
        "\n",
        "This notebook uses [Haystack 2.0](https://docs.haystack.deepset.ai/v2.0/docs/intro) to compare the results of sending the same prompt to several different models.\n",
        "\n",
        "This is a very basic demo where you can only compare a few models that support streaming responses. I'd like to support more models in the future, so watch this space for updates.\n",
        "\n",
        "### Models\n",
        "\n",
        "Haystack's [OpenAIGenerator](https://docs.haystack.deepset.ai/v2.0/docs/openaigenerator) and [CohereGenerator](https://docs.haystack.deepset.ai/v2.0/docs/coheregenerator) support streaming out of the box.\n",
        "\n",
        "The other models use the [HuggingFaceTGIGenerator](https://docs.haystack.deepset.ai/v2.0/docs/huggingfacetgigenerator) and have [hosted inference endpoints](https://huggingface.co/inference-api).\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "You need [HuggingFace](https://huggingface.co/docs/hub/security-tokens), [Cohere](https://docs.cohere.com/docs/connector-authentication), and [OpenAI](https://help.openai.com/en/articles/4936850-where-do-i-find-my-api-key) API keys. Save them as secrets in your Colab. Click on the key icon in the left menu or [see detailed instructions here](https://medium.com/@parthdasawant/how-to-use-secrets-in-google-colab-450c38e3ec75)."
      ],
      "metadata": {
        "id": "T8zE8SbZ0wUz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKjba4xoWzdX",
        "outputId": "85a5f535-dee5-4076-f744-fb6311e4f359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting haystack-ai\n",
            "  Downloading haystack_ai-2.0.0b5-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cohere_haystack\n",
            "  Downloading cohere_haystack-0.2.0-py3-none-any.whl (15 kB)\n",
            "Collecting boilerpy3 (from haystack-ai)\n",
            "  Downloading boilerpy3-1.0.7-py3-none-any.whl (22 kB)\n",
            "Collecting haystack-bm25 (from haystack-ai)\n",
            "  Downloading haystack_bm25-1.0.2-py2.py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (3.1.3)\n",
            "Collecting lazy-imports (from haystack-ai)\n",
            "  Downloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (10.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (3.2.1)\n",
            "Collecting openai>=1.1.0 (from haystack-ai)\n",
            "  Downloading openai-1.9.0-py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.4/223.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (1.5.3)\n",
            "Collecting posthog (from haystack-ai)\n",
            "  Downloading posthog-3.3.2-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (6.0.1)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (8.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (4.5.0)\n",
            "Collecting cohere (from cohere_haystack)\n",
            "  Downloading cohere-4.44-py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->haystack-ai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.1.0->haystack-ai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->haystack-ai) (1.3.0)\n",
            "Collecting typing-extensions (from haystack-ai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere->cohere_haystack) (3.9.1)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere->cohere_haystack)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro<2.0,>=1.8 (from cohere->cohere_haystack)\n",
            "  Downloading fastavro-1.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib_metadata<7.0,>=6.0 (from cohere->cohere_haystack)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere->cohere_haystack) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere->cohere_haystack) (2.0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from haystack-bm25->haystack-ai) (1.23.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->haystack-ai) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->haystack-ai) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog->haystack-ai)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->cohere_haystack) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->cohere_haystack) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->cohere_haystack) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->cohere_haystack) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->cohere_haystack) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere->cohere_haystack) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->haystack-ai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->haystack-ai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.1.0->haystack-ai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere->cohere_haystack) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere->cohere_haystack) (3.3.2)\n",
            "Installing collected packages: monotonic, typing-extensions, lazy-imports, importlib_metadata, haystack-bm25, h11, fastavro, boilerpy3, backoff, posthog, httpcore, httpx, cohere, openai, haystack-ai, cohere_haystack\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib-metadata 7.0.1\n",
            "    Uninstalling importlib-metadata-7.0.1:\n",
            "      Successfully uninstalled importlib-metadata-7.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 boilerpy3-1.0.7 cohere-4.44 cohere_haystack-0.2.0 fastavro-1.9.3 h11-0.14.0 haystack-ai-2.0.0b5 haystack-bm25-1.0.2 httpcore-1.0.2 httpx-0.26.0 importlib_metadata-6.11.0 lazy-imports-0.3.1 monotonic-1.6 openai-1.9.0 posthog-3.3.2 typing-extensions-4.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install haystack-ai cohere_haystack"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.components.builders.prompt_builder import PromptBuilder\n",
        "from haystack.components.generators import OpenAIGenerator\n",
        "from cohere_haystack.generator import CohereGenerator\n",
        "from haystack.components.generators import HuggingFaceTGIGenerator\n",
        "from google.colab import userdata\n",
        "\n",
        "open_ai_generator = OpenAIGenerator(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "cohere_generator = CohereGenerator(api_key=userdata.get('COHERE_API_KEY'))\n",
        "\n",
        "hf_generator = HuggingFaceTGIGenerator(model=\"mistralai/Mistral-7B-v0.1\",token=userdata.get('HF_API_KEY'))\n",
        "\n",
        "hf_generator.warm_up()\n",
        "\n",
        "hf_generator_2 = HuggingFaceTGIGenerator(model=\"tiiuae/falcon-7b-instruct\",token=userdata.get('HF_API_KEY'))\n",
        "\n",
        "hf_generator_2.warm_up()\n",
        "\n",
        "hf_generator_3 = HuggingFaceTGIGenerator(model=\"bigscience/bloom\",token=userdata.get('HF_API_KEY'))\n",
        "\n",
        "hf_generator_3.warm_up()\n",
        "\n"
      ],
      "metadata": {
        "id": "XWsAANJxXLaH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.components.generators import GPTGenerator\n",
        "MODELS: list[GPTGenerator] = [cohere_generator, open_ai_generator, hf_generator, hf_generator_2, hf_generator_3]"
      ],
      "metadata": {
        "id": "9_xznJXWe1M8"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `AppendToken` dataclass formats the output so that the model name is printed, and the text follows in chunks of 5 tokens."
      ],
      "metadata": {
        "id": "zZsKIVCQ5mJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "import ipywidgets as widgets\n",
        "\n",
        "def output():...\n",
        "\n",
        "@dataclass\n",
        "class AppendToken:\n",
        "  output: widgets.Output\n",
        "  chunks = []\n",
        "  chunk_size = 5\n",
        "\n",
        "  def __call__(self, chunk):\n",
        "      with self.output:\n",
        "        text = getattr(chunk, 'content', '') or getattr(chunk, 'text', '') or ''\n",
        "        self.chunks.append(text)\n",
        "        if len(self.chunks) == self.chunk_size:\n",
        "          output_string = ' '.join(self.chunks)\n",
        "          self.output.append_display_data(output_string)\n",
        "          self.chunks.clear()\n",
        "\n",
        "def multiprompt(prompt, models=MODELS):\n",
        "  outputs = [widgets.Output(layout={'border': '1px solid black'}) for _ in models]\n",
        "  display(widgets.HBox(children=outputs))\n",
        "\n",
        "  for i, model in enumerate(models):\n",
        "    model_name = getattr(model, 'model', '') or getattr(model, 'model_name', '') or ''\n",
        "    outputs[i].append_display_data(f'Model name: {model_name}')\n",
        "    model.streaming_callback = AppendToken(outputs[i])\n",
        "    model.run(prompt)\n"
      ],
      "metadata": {
        "id": "g1wwjOJVejJF"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multiprompt(\"Give me a 50-word description of a beach sunset in the style of Sherlock Holmes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372,
          "referenced_widgets": [
            "5e061067281e46c3a0e13850ded2da0e",
            "be7d41d0ba44405e84abc7cc1e32efb2",
            "7ebcad8075f74d6f91d8ae4e105bf4b4",
            "e606a9b359484f80b821197029c419af",
            "c89920b1edb849b0a8625166c61e2d22",
            "f3a8a94eba894e098414ab9ecb288588",
            "7146c96d346d43e78e22fe663e501078",
            "eda89ff2ee0a46909205059af92ee220",
            "6b13f90fe4664ae78f6e3a04a63c94aa",
            "c0bb1da133254ac995a1d07320b60d5d",
            "a8c1ae0b06ae42deb6e777be1952e509",
            "40d6dfe4bbcb4925a1d95c3fe60592a1"
          ]
        },
        "id": "O0CSf3f2gLfe",
        "outputId": "d081663b-4741-469e-a63d-16af19499545"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Output(layout=Layout(border='1px solid black')), Output(layout=Layout(border='1px solid black')…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e061067281e46c3a0e13850ded2da0e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This was a very silly example prompt. If you found this demo useful, let me know the kinds of prompts you tested it with! tilde.thurium@deepset.ai.Thanks for following along!"
      ],
      "metadata": {
        "id": "t2IUAyLyOfeO"
      }
    }
  ]
}